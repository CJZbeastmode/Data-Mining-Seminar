\section{Motivation}
One of the most important ascpects of machine learning is classification. Typical algorithms and models
that are used for classification include logistic regression, naive bayes, decision trees and so on. In the early 90s, 
Vladimir Vapnik and his colleagues developed a new algorithm called Support Vector Machine (SVM), which is an algorithm 
that is optimized for classification and regression analysis. In this paper,
we will focus on the main usages of SVM, including the generalization of linear decision boundaries for classification.
We will also discuss the role of kernel in SVM, as well as the implementation, evalution methods, application and many
different aspects of SVM.
